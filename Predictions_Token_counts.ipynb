{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prediction models for balanced and imblaced dataset for token count features\n",
    "\n",
    "Step1: Creation of the features (1-gram, 2-gram, 3-gram, tf-idf, all)\n",
    "Step2: Division of data in train and test set\n",
    "Step3: Perform 10-fold Cross Validation for Imbalanced train set\n",
    "Step4: Classification for Imbalanced train set (Logistic Regression, CART, Naive Bayes, Linear SVM)\n",
    "Step5: Balance train set\n",
    "Step6: Perform 10-fold Cross Validation for Imbalanced train set\n",
    "Step7: Classification for Balanced train set (Logistic Regression, CART, Naive Bayes, Linear SVM)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "#https://pypi.org/project/scikit-plot/\n",
    "# https://scikit-plot.readthedocs.io/en/stable/metrics.html\n",
    "import scikitplot as skplt \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Preprocessed.pkl', 'rb') as handle:\n",
    "    Preprocessed = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Numerical_Features.pkl', 'rb') as handle:\n",
    "    numerical_features = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Features = pd.concat([Preprocessed, numerical_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pred= [c for c in Features.columns.values if c  not in ['Label','Emojie','POS']]\n",
    "\n",
    "numeric_features= [c for c in Features.columns.values if c   in ['Length','Words','Avg_word_length','Punctuation']]\n",
    "target = 'Label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/baghern/a-deep-dive-into-sklearn-pipelines\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(feature_type,key):\n",
    "    \n",
    "    \n",
    "    unigram =  Pipeline([\n",
    "                ('selector', TextSelector(key= key)),\n",
    "                ('unigram', CountVectorizer(ngram_range= (1,1)))\n",
    "            ])\n",
    "    bigram =  Pipeline([\n",
    "                ('selector', TextSelector(key= key)),\n",
    "                ('bigram', CountVectorizer(ngram_range = (2,2)))\n",
    "            ])\n",
    "    \n",
    "    trigram =  Pipeline([\n",
    "                ('selector', TextSelector(key= key)),\n",
    "                ('trigram', CountVectorizer(ngram_range = (3,3)))\n",
    "            ])\n",
    "    tfidf =  Pipeline([\n",
    "                ('selector', TextSelector(key= key)),\n",
    "                ('tfidf', TfidfVectorizer())\n",
    "            ])\n",
    "    \n",
    "    all_text = FeatureUnion([\n",
    "            ('unigram', unigram),\n",
    "            ('bigram', bigram),\n",
    "            ('trigram',trigram),\n",
    "            ('tfidf',tfidf)])\n",
    "    \n",
    "    all_text = Pipeline([('all_text', all_text)])\n",
    "    \n",
    "    if (feature_type == \"1gram\"):\n",
    "            \n",
    "        pipeline = unigram\n",
    "\n",
    "    elif (feature_type == \"2gram\"):\n",
    "        \n",
    "        pipeline = bigram\n",
    "\n",
    "        \n",
    "    elif (feature_type == \"3gram\"):\n",
    "        \n",
    "        pipeline = trigram\n",
    "\n",
    "    \n",
    "    elif (feature_type == \"tfidf\"):\n",
    "        \n",
    "        pipeline = tfidf\n",
    "\n",
    "    \n",
    "    elif (feature_type == \"all_text\"):\n",
    "        \n",
    "        pipeline = all_text\n",
    "\n",
    "    print(\"Vectorizer \",feature_type, \" has been created. \\n\\n\")\n",
    "\n",
    "    return pipeline\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced(X_train, Y_train, pipe, balance):\n",
    "    \n",
    "    if (balance == 0):\n",
    "   \n",
    "        models = []\n",
    "\n",
    "        models.append(('LR',Pipeline([(\"pipe\",pipe),\n",
    "            ( 'LR',LogisticRegression(solver='liblinear', multi_class='ovr'))])))\n",
    "        models.append(('CART', Pipeline([(\"pipe\",pipe),\n",
    "            ('CART',DecisionTreeClassifier())]))) \n",
    "        models.append(('NB', Pipeline([(\"pipe\",pipe),\n",
    "              ('NB',MultinomialNB())])))\n",
    "        models.append(('SVM', Pipeline([(\"pipe\",pipe),\n",
    "            ('SVM',LinearSVC())])))\n",
    "        \n",
    "        \n",
    "    elif (balance == 1):\n",
    "        models = []\n",
    "\n",
    "        models.append(('LR',Pipeline([(\"pipe\",pipe),\n",
    "            ( 'LR',LogisticRegression(solver='liblinear', multi_class='ovr'))])))\n",
    "        models.append(('SVM', Pipeline([(\"pipe\",pipe),\n",
    "            ('SVM',LinearSVC())])))\n",
    "        \n",
    "        X = pd.concat([X_train, Y_train], axis=1)\n",
    "        X.head(5)\n",
    "        \n",
    "        hate = X[X.Label==\"Explicit\"]\n",
    "        no_hate = X[X.Label==\"No hate\"]\n",
    "        \n",
    "        no_hate_upsampled = resample(no_hate,\n",
    "                          replace=True, \n",
    "                          n_samples=len(no_hate), \n",
    "                          random_state=27)\n",
    "\n",
    "        # combine majority and upsampled minority\n",
    "        upsampled = pd.concat([hate, no_hate_upsampled])\n",
    " \n",
    "        upsampled.Label.value_counts()\n",
    "        \n",
    "        Y_train = upsampled.Label\n",
    "        X_train = upsampled.drop('Label', axis=1)\n",
    "        \n",
    "    return([Y_train, X_train, models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(pipe, balance):\n",
    "    \n",
    "    Y_train = balance[0]\n",
    "    X_train = balance[1]\n",
    "    models = balance[2]\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    seed = 7\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "        cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_test, Y_test, pipe, balance):\n",
    "        \n",
    "    Y_train = balance[0]\n",
    "    X_train = balance[1]\n",
    "    models = balance[2]\n",
    "        \n",
    "    for name, model in models:\n",
    "\n",
    "        print(\"Prediction for \",name)\n",
    "\n",
    "        model.fit(X_train, Y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        \n",
    "        print(\"Accuracy Score \\n\",accuracy_score(Y_test, predictions),\"\\n\")\n",
    "        print(\"Confusion Matrix \\n\",confusion_matrix(Y_test, predictions),\"\\n\")\n",
    "        print(\"Classification Report \\n\",classification_report(Y_test, predictions),\"\\n\\n\")\n",
    "        print(\"Confusion matrix plot\")\n",
    "        \n",
    "        skplt.metrics.plot_confusion_matrix(Y_test, predictions, normalize=False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Features[features_pred], Features[target], test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "for i in range (1):\n",
    "\n",
    "    if (i==0):\n",
    "        print(\"IMBALANCED DATASET \",i)\n",
    "        features = []\n",
    "        features.append(\"1gram\")\n",
    "        features.append(\"2gram\")\n",
    "        features.append(\"3gram\")\n",
    "        features.append(\"tfidf\")\n",
    "        features.append(\"all_text\")\n",
    "\n",
    "        keys = ['NoLaugh','Stemming','NoPunctuation']\n",
    "        \n",
    "       \n",
    "        \n",
    "    \n",
    "    elif (i==1):\n",
    "        print(\"BALANCED DATASET \", i)\n",
    "        features = []\n",
    "        features.append(\"1gram\")\n",
    "        features.append(\"tfidf\")\n",
    "        features.append(\"all_text\")\n",
    "\n",
    "        keys = ['Stemming']\n",
    "        \n",
    "\n",
    "    for key in keys:\n",
    "        for name in features:\n",
    "            print (\"Column name :\", key)\n",
    "\n",
    "            pipe = vectorizer(name,key)\n",
    "            balance = balanced(X_train, Y_train, pipe, i)\n",
    "            \n",
    "            if (name==\"1gram\"):\n",
    "\n",
    "                print(\"Dummy Here!\")\n",
    "\n",
    "                pipeline_dummy = make_pipeline(pipe,  DummyClassifier(strategy='most_frequent', random_state=0))\n",
    "                pipeline_dummy.fit(X_train, Y_train)\n",
    "                predictions = pipeline_dummy.predict(X_test)\n",
    "\n",
    "                print(\"Accuracy Score \\n\",accuracy_score(Y_test, predictions),\"\\n\")\n",
    "                print(\"Confusion Matrix \\n\",confusion_matrix(Y_test, predictions),\"\\n\")\n",
    "                print(\"Classification Report \\n\",classification_report(Y_test, predictions),\"\\n\\n\")\n",
    "\n",
    "\n",
    "            model_accuracy( pipe,balance)\n",
    "\n",
    "            prediction(X_test, Y_test, pipe, balance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
